**‚ö†Ô∏è KRYTYCZNE: Przed rozpoczƒôciem pracy zapoznaj siƒô z og√≥lnymi zasadami refaktoryzacji, poprawek i testowania opisanymi w pliku [refactoring_rules.md](../../_BASE_/refactoring_rules.md).**

---

# üìã ETAP 3: SCANNER_CORE - ANALIZA I REFAKTORYZACJA

**Data analizy:** 2025-01-28

### üìã Identyfikacja

- **Plik g≈Ç√≥wny:** `src/logic/scanner_core.py`
- **Plik z kodem (patch):** `../patches/scanner_core_patch_code.md`
- **Priorytet:** ‚ö´‚ö´‚ö´‚ö´ KRYTYCZNY
- **Zale≈ºno≈õci:**
  - `src/app_config.py` (konfiguracja cache i rozszerze≈Ñ)
  - `src/logic/file_pairing.py` (parowanie plik√≥w)
  - `src/logic/metadata_manager.py` (metadane folder√≥w)
  - `src/logic/scanner_cache.py` (cache skanowania)
  - `src/models/file_pair.py` (model par plik√≥w)
  - `src/models/special_folder.py` (foldery specjalne)
  - `src/utils/path_utils.py` (operacje na ≈õcie≈ºkach)

---

### üîç Analiza problem√≥w

1.  **B≈Çƒôdy krytyczne:**

    - **Potencjalne memory leaks w collect_files_streaming**: Memory cleanup (linie 366-369) jest wykonywany co 1000 plik√≥w, ale w przypadku przerwania skanowania mo≈ºe nie zostaƒá wywo≈Çany, co prowadzi do memory leaks
    - **Thread safety issue w progress reporting**: Mimo ThreadSafeProgressManager, w funkcji `_walk_directory_streaming` istnieje direct access do `progress_callback` (linie 277-287) bez proper locking
    - **Race condition w visited_dirs**: Set `visited_dirs` (linia 267) nie jest thread-safe i mo≈ºe powodowaƒá race conditions przy concurrent access
    - **Incomplete error handling dla critical operations**: Funkcja `collect_files_streaming` nie ma proper recovery dla MemoryError i mo≈ºe crash ca≈ÇƒÖ aplikacjƒô

2.  **Optymalizacje:**

    - **Inefficient progress calculation**: Aproksymacja progressu (linia 281) u≈ºywa `total_folders_scanned * 2` co nie odzwierciedla rzeczywistego postƒôpu
    - **Suboptimal batch processing**: R√≥≈ºne batch sizes (50, 20) w r√≥≈ºnych miejscach mogƒÖ byƒá zoptymalizowane na podstawie performance testing
    - **Cache efficiency**: Smart pre-filtering (linie 316-332) mo≈ºe byƒá dalej zoptymalizowane przez early directory rejection
    - **Memory management**: GC call co 1000 plik√≥w (linie 366-369) mo≈ºe byƒá zbyt czƒôste i wp≈Çywaƒá na performance

3.  **Refaktoryzacja:**

    - **Complex nested function**: `_walk_directory_streaming` (linie 269-425) jest zbyt d≈Çuga i complex - potrzebuje dekompozycji
    - **Mixed responsibilities**: Funkcja ≈ÇƒÖczy file scanning, progress reporting, memory management i error handling
    - **Inconsistent logging levels**: Mieszanie DEBUG, INFO, WARNING, ERROR bez clear criteria
    - **Dead code comments**: Komentarze o usuniƒôtych klasach (linie 56, 59, 182, 598-600) powinny byƒá usuniƒôte

4.  **Logowanie:**
    - **Performance logging inconsistency**: Business metrics (linie 441-446) sƒÖ logged na INFO level, ale performance warnings (linie 449-453) u≈ºywajƒÖ WARNING
    - **Excessive debug logging**: Debug logs w critical path mogƒÖ wp≈Çywaƒá na performance przy du≈ºych zbiorach danych
    - **Missing correlation IDs**: Brak identyfikator√≥w sesji skanowania dla tracking distributed operations

---

### üõ†Ô∏è PLAN REFAKTORYZACJI

**Typ refaktoryzacji:** Podzia≈Ç pliku / Optymalizacja kodu / Poprawa thread safety / Memory management

#### KROK 1: PRZYGOTOWANIE üõ°Ô∏è

- [ ] **BACKUP UTWORZONY:** `scanner_core_backup_2025_01_28.py` w folderze `AUDYT/backups/`
- [ ] **ANALIZA ZALE≈ªNO≈öCI:** Sprawdzenie wszystkich imports i integration points
- [ ] **IDENTYFIKACJA API:** Lista publicznych funkcji - `collect_files_streaming()`, `scan_folder_for_pairs()`, `get_scan_statistics()`
- [ ] **PLAN ETAPOWY:** Podzia≈Ç na ma≈Çe, weryfikowalne kroki z preserved functionality

#### KROK 2: IMPLEMENTACJA üîß

- [ ] **ZMIANA 1:** Dekompozycja `_walk_directory_streaming` na mniejsze, focused functions
- [ ] **ZMIANA 2:** Poprawa thread safety - thread-safe visited_dirs, proper locking for all shared state
- [ ] **ZMIANA 3:** Enhanced memory management - proper cleanup w finally blocks, configurable GC intervals
- [ ] **ZMIANA 4:** Progress calculation optimization - accurate progress based on estimated total files
- [ ] **ZMIANA 5:** Standardization logging levels i dodanie session correlation IDs
- [ ] **ZMIANA 6:** Error handling improvement - comprehensive recovery strategies dla critical errors
- [ ] **ZACHOWANIE API:** Wszystkie public functions zachowane z identycznymi signatures
- [ ] **BACKWARD COMPATIBILITY:** 100% kompatybilno≈õƒá wsteczna zachowana

#### KROK 3: WERYFIKACJA PO KA≈ªDEJ ZMIANIE üß™

- [ ] **TESTY AUTOMATYCZNE:** Uruchomienie test√≥w scanner_core po ka≈ºdej zmianie
- [ ] **URUCHOMIENIE APLIKACJI:** Sprawdzenie czy skanowanie folder√≥w dzia≈Ça
- [ ] **WERYFIKACJA FUNKCJONALNO≈öCI:** Test na pr√≥bkach 1000+, 10000+ plik√≥w

#### KROK 4: INTEGRACJA FINALNA üîó

- [ ] **TESTY INNYCH PLIK√ìW:** Sprawdzenie czy scanning_service.py i UI components dzia≈ÇajƒÖ
- [ ] **TESTY INTEGRACYJNE:** Pe≈Çne testy skanowania z cache i metadata management
- [ ] **TESTY WYDAJNO≈öCIOWE:** Weryfikacja 100+ plik√≥w/s dla folder√≥w >500 plik√≥w, memory usage monitoring

#### KRYTERIA SUKCESU REFAKTORYZACJI ‚úÖ

- [ ] **WSZYSTKIE TESTY PASS** - 100% test√≥w przechodzi
- [ ] **APLIKACJA URUCHAMIA SIƒò** - bez b≈Çƒôd√≥w w skanowaniu
- [ ] **FUNKCJONALNO≈öƒÜ ZACHOWANA** - skanowanie dzia≈Ça identycznie
- [ ] **KOMPATYBILNO≈öƒÜ WSTECZNA** - wszystkie existing integrations dzia≈ÇajƒÖ
- [ ] **PERFORMANCE MAINTAINED** - 100+ plik√≥w/s maintained, memory managed
- [ ] **THREAD SAFETY** - zero race conditions w concurrent scanning

---

### üß™ PLAN TEST√ìW AUTOMATYCZNYCH

**Test funkcjonalno≈õci podstawowej:**

- Test `collect_files_streaming()` na r√≥≈ºnych rozmiarach folder√≥w (100, 1000, 10000 plik√≥w)
- Test `scan_folder_for_pairs()` z r√≥≈ºnymi strategiami parowania
- Test interrupt mechanism - cancellation podczas skanowania
- Test cache operations - hit/miss scenarios, cache invalidation
- Test special folders handling - virtual folders creation

**Test integracji:**

- Test integracji z file_pairing.py - pipeline collect + create_pairs
- Test integracji z metadata_manager.py - special folders z metadata
- Test integracji z scanner_cache.py - proper cache lifecycle
- Test integracji z path_utils.py - path normalization scenarios

**Test wydajno≈õci:**

- Benchmark `collect_files_streaming()` - target 100+ plik√≥w/s dla >500 plik√≥w
- Memory profiling - monitor memory usage growth podczas long scans
- Progress reporting performance - ensure progress callbacks nie blokujƒÖ scanning
- Cache performance - hit ratio optimization, cache overhead measurement

**Test thread safety:**

- Concurrent scanning multiple directories simultaneously
- Interrupt handling podczas concurrent operations
- Thread safety visited_dirs i progress reporting
- Memory consistency checks under concurrent load

**Test error handling:**

- PermissionError handling - continue scanning other directories
- FileNotFoundError handling - directory deleted during scan
- MemoryError handling - proper cleanup i recovery
- ScanningInterrupted exception - proper resource cleanup

---

### üìä STATUS TRACKING

- [ ] Backup utworzony
- [ ] Plan refaktoryzacji przygotowany
- [ ] Kod zaimplementowany (krok po kroku)
- [ ] Testy podstawowe przeprowadzone (PASS)
- [ ] Testy integracji przeprowadzone (PASS)
- [ ] **WERYFIKACJA FUNKCJONALNO≈öCI** - test na 10000+ plik√≥w, interrupt handling
- [ ] **WERYFIKACJA ZALE≈ªNO≈öCI** - sprawdzenie file_pairing.py, metadata_manager.py integration
- [ ] **WERYFIKACJA WYDAJNO≈öCI** - benchmark 100+ plik√≥w/s, memory profiling
- [ ] **WERYFIKACJA THREAD SAFETY** - concurrent scanning tests
- [ ] **WERYFIKACJA ERROR HANDLING** - recovery scenarios, resource cleanup
- [ ] Dokumentacja zaktualizowana
- [ ] **Gotowe do wdro≈ºenia**

---

### üéØ BUSINESS IMPACT

**Krytyczny wp≈Çyw na procesy biznesowe:**
- G≈Ç√≥wny silnik skanowania - podstawa discovery plik√≥w w aplikacji
- Wydajno≈õƒá 100+ plik√≥w/s dla folder√≥w >500 plik√≥w - krytyczna dla user experience
- Thread safety - stabilno≈õƒá podczas concurrent operations
- Memory management - zapewnienie stable operation przy du≈ºych zbiorach danych
- Error handling - robust operation w production environment

**Metryki sukcesu:**
- Czas skanowania 1000 plik√≥w: <10 sekund (100+ plik√≥w/s)
- Memory usage podczas skanowania: <200MB per 10000 plik√≥w
- Thread safety: zero race conditions w concurrent scanning tests
- Error recovery: 100% recovery from non-critical errors (permissions, file access)
- Cache efficiency: >80% cache hit ratio dla repeat scans
- Progress accuracy: <5% deviation between reported i actual progress

**Obszary optymalizacji:**
- Smart pre-filtering: reduce unnecessary directory traversal
- Memory management: efficient cleanup preventing leaks
- Progress calculation: accurate estimation based na directory size estimation
- Batch processing: optimal batch sizes dla different operations
- Error handling: comprehensive recovery strategies for production stability